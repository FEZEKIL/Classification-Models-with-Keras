{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAe3pNMp+dUYoLX4Zy95nv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FEZEKIL/Classification-Models-with-Keras/blob/main/Classification-Models-with-Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Models with Keras"
      ],
      "metadata": {
        "id": "J-uDnkWstuIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hQ6BEiLrtr3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hk0Br_Vta2W",
        "outputId": "459d1234-9e34-48d2-8725-fdd92bc9fb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_cpu==2.18.0\n",
            "  Downloading tensorflow_cpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow_cpu==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_cpu\n",
            "Successfully installed tensorflow_cpu-2.18.0\n",
            "Collecting matplotlib==3.9.2\n",
            "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
            "Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "Successfully installed matplotlib-3.9.2\n",
            "==== All required libraries are installed =====\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_cpu==2.18.0\n",
        "!pip install matplotlib==3.9.2\n",
        "\n",
        "print(\"==== All required libraries are installed =====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppress the tensorflow warning messages\n",
        "We use the following code to suppress the warning messages due to use of CPU architechture for tensoflow.\n",
        "\n",
        "You may want to comment out these lines if you are using the GPU architechture"
      ],
      "metadata": {
        "id": "PWALZjcPuTX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "iODEI-xKuVan"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "iZcD1yPtuju2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are dealing we images, let's also import the Matplotlib scripting layer in order to view the images."
      ],
      "metadata": {
        "id": "_YH5OB5Auwgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hFOv4vIDuynH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# read the data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KC2b1FPvAZa",
        "outputId": "59e6b10e-f8de-433e-e637-3c43677e6fa0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_8V8hSvPI5",
        "outputId": "062d010f-624f-421d-fa85-f94d7e49d2f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first number in the output tuple is the number of images, and the other two numbers are the size of the images in datset. So, each image is 28 pixels by 28 pixels.\n",
        "\n",
        "Let's visualize the first image in the training set using Matplotlib's scripting layer."
      ],
      "metadata": {
        "id": "ZaDf99kXvk_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "TQ8q8SJ7vbud",
        "outputId": "f739b9b5-4cf2-42cc-a059-271219b8b3f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a64982e7150>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With conventional neural networks, we cannot feed in the image as input as is. So we need to flatten the images into one-dimensional vectors, each of size 1 x (28 x 28) = 1 x 784."
      ],
      "metadata": {
        "id": "EmH1liQXv1G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten images into one-dimensional vector\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"
      ],
      "metadata": {
        "id": "nOUiKgzev2mJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1."
      ],
      "metadata": {
        "id": "LCbtBPG2wI04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "LrgwwNiVwKoq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, before we start building our model, remember that for classification we need to divide our target variable into categories. We use the to_categorical function from the Keras Utilities package."
      ],
      "metadata": {
        "id": "UU447vaswYd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1amX4xjgwaFj",
        "outputId": "e43912dd-335f-4a19-9eef-3ac966450233"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Neural Network"
      ],
      "metadata": {
        "id": "3N4BTOrbwph1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define classification model\n",
        "def classification_model():\n",
        "    # create model\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(num_pixels,)))\n",
        "    model.add(Dense(num_pixels, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "MIpAhxU0wrlu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test the Network"
      ],
      "metadata": {
        "id": "IG7_NQPQw0nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = classification_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmRQv8Wtw6lP",
        "outputId": "f482e296-ab84-4991-91a1-b123ef1bbcda"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 22s - 12ms/step - accuracy: 0.9438 - loss: 0.1838 - val_accuracy: 0.9703 - val_loss: 0.0943\n",
            "Epoch 2/10\n",
            "1875/1875 - 41s - 22ms/step - accuracy: 0.9758 - loss: 0.0772 - val_accuracy: 0.9708 - val_loss: 0.1009\n",
            "Epoch 3/10\n",
            "1875/1875 - 22s - 12ms/step - accuracy: 0.9830 - loss: 0.0543 - val_accuracy: 0.9714 - val_loss: 0.0923\n",
            "Epoch 4/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9872 - loss: 0.0401 - val_accuracy: 0.9719 - val_loss: 0.1045\n",
            "Epoch 5/10\n",
            "1875/1875 - 22s - 12ms/step - accuracy: 0.9894 - loss: 0.0320 - val_accuracy: 0.9786 - val_loss: 0.0772\n",
            "Epoch 6/10\n",
            "1875/1875 - 40s - 21ms/step - accuracy: 0.9917 - loss: 0.0252 - val_accuracy: 0.9784 - val_loss: 0.0751\n",
            "Epoch 7/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9930 - loss: 0.0210 - val_accuracy: 0.9794 - val_loss: 0.0834\n",
            "Epoch 8/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.9794 - val_loss: 0.0908\n",
            "Epoch 9/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.9799 - val_loss: 0.0931\n",
            "Epoch 10/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9773 - val_loss: 0.1196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7_7InFbyftv",
        "outputId": "b2827262-36e8-44be-a854-e4deab0bce96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772999882698059% \n",
            " Error: 0.022700011730194092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classification_model.keras')"
      ],
      "metadata": {
        "id": "kajEjQityyrM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = keras.saving.load_model('classification_model.keras')"
      ],
      "metadata": {
        "id": "GX-PNeCjy7is"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_model_6layers():\n",
        "    # create model\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(num_pixels,)))\n",
        "    model.add(Dense(num_pixels, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model_6layers = classification_model_6layers()\n",
        "\n",
        "# fit the model\n",
        "model_6layers.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores_6layers = model_6layers.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print('Accuracy_3_layers: {}% \\n Accuracy_6_layers: {}'.format(scores[1], scores_6layers[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RtiqWzkzOjx",
        "outputId": "bafe3882-6ba4-4124-bdd0-47146d9b8d94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 24s - 13ms/step - accuracy: 0.9334 - loss: 0.2230 - val_accuracy: 0.9650 - val_loss: 0.1067\n",
            "Epoch 2/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9711 - loss: 0.0994 - val_accuracy: 0.9678 - val_loss: 0.1059\n",
            "Epoch 3/10\n",
            "1875/1875 - 43s - 23ms/step - accuracy: 0.9772 - loss: 0.0760 - val_accuracy: 0.9767 - val_loss: 0.0859\n",
            "Epoch 4/10\n",
            "1875/1875 - 40s - 22ms/step - accuracy: 0.9834 - loss: 0.0559 - val_accuracy: 0.9787 - val_loss: 0.0797\n",
            "Epoch 5/10\n",
            "1875/1875 - 23s - 12ms/step - accuracy: 0.9862 - loss: 0.0474 - val_accuracy: 0.9767 - val_loss: 0.0836\n",
            "Epoch 6/10\n",
            "1875/1875 - 40s - 21ms/step - accuracy: 0.9881 - loss: 0.0408 - val_accuracy: 0.9782 - val_loss: 0.0771\n",
            "Epoch 7/10\n",
            "1875/1875 - 22s - 12ms/step - accuracy: 0.9901 - loss: 0.0334 - val_accuracy: 0.9815 - val_loss: 0.0746\n",
            "Epoch 8/10\n",
            "1875/1875 - 41s - 22ms/step - accuracy: 0.9916 - loss: 0.0296 - val_accuracy: 0.9796 - val_loss: 0.0842\n",
            "Epoch 9/10\n",
            "1875/1875 - 40s - 21ms/step - accuracy: 0.9921 - loss: 0.0272 - val_accuracy: 0.9820 - val_loss: 0.0787\n",
            "Epoch 10/10\n",
            "1875/1875 - 42s - 22ms/step - accuracy: 0.9927 - loss: 0.0249 - val_accuracy: 0.9816 - val_loss: 0.0837\n",
            "Accuracy_3_layers: 0.9772999882698059% \n",
            " Accuracy_6_layers: 0.9815999865531921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "pretrained_model = keras.saving.load_model('classification_model.keras')\n",
        "\n",
        "print(\"Pre-trained model loaded successufully\")\n",
        "\n",
        "# Further train the loaded model\n",
        "pretrained_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores_20_epochs = pretrained_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy_10_epochs: {}% \\n Accuracy_20_epochs: {}'.format(scores[1], scores_20_epochs[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOa-v1Pf0zY2",
        "outputId": "b8215953-4ef3-4c82-c1d5-c17cfc49da7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained model loaded successufully\n",
            "Epoch 1/10\n",
            "1875/1875 - 22s - 12ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.9829 - val_loss: 0.0831\n",
            "Epoch 2/10\n",
            "1875/1875 - 40s - 21ms/step - accuracy: 0.9958 - loss: 0.0142 - val_accuracy: 0.9826 - val_loss: 0.0930\n",
            "Epoch 3/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9796 - val_loss: 0.1037\n",
            "Epoch 4/10\n",
            "1875/1875 - 20s - 10ms/step - accuracy: 0.9962 - loss: 0.0134 - val_accuracy: 0.9807 - val_loss: 0.0913\n",
            "Epoch 5/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9826 - val_loss: 0.1029\n",
            "Epoch 6/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9965 - loss: 0.0130 - val_accuracy: 0.9812 - val_loss: 0.0975\n",
            "Epoch 7/10\n",
            "1875/1875 - 20s - 10ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.9803 - val_loss: 0.1054\n",
            "Epoch 8/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9974 - loss: 0.0092 - val_accuracy: 0.9772 - val_loss: 0.1263\n",
            "Epoch 9/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.9806 - val_loss: 0.1267\n",
            "Epoch 10/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9826 - val_loss: 0.1131\n",
            "Accuracy_10_epochs: 0.9772999882698059% \n",
            " Accuracy_20_epochs: 0.9825999736785889\n"
          ]
        }
      ]
    }
  ]
}